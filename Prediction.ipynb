{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "from lib.loader import load_data, iterate_sentence\n",
    "from lib.ml import add_feature\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "TRAINING_DATA = os.path.join(DATA_DIR, \"Laptops_Train_v2.xml\")\n",
    "TESTING_DATA = os.path.join(DATA_DIR, \"Laptops_Test_Gold.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "import regex as re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "# this regex is taken from NLTK's WordPunctTokenizer\n",
    "infix_re = re.compile(r'\\w+|[^\\w\\s]+')\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "\n",
    "nlp.tokenizer = custom_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_full_info = list(iterate_sentence(TRAINING_DATA, nlp))\n",
    "test_full_info = list(iterate_sentence(TESTING_DATA, nlp))\n",
    "train_sents = [list(zip(s[0], s[4])) for s in train_full_info]\n",
    "test_sents = [list(zip(s[0], s[4])) for s in test_full_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_to_features(token, sent, no_embedding=False):\n",
    "    loc = token.i\n",
    "    sent_token_sum = len(sent)\n",
    "    \n",
    "    \n",
    "    contain_upper_fn = lambda t: int(len([c for c in t.text if c.isupper()])!=0)\n",
    "    \n",
    "    # current token feature\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"relative_loc\": loc/float(sent_token_sum),\n",
    "        \"len\": len(token.text),\n",
    "        \"pos\": token.pos_,\n",
    "        \"detailed_pos\": token.tag_,\n",
    "        \"dep\": token.dep_,\n",
    "        \"vector_l2_norm\": token.vector_norm, \n",
    "        \"like_num\": int(token.like_num),\n",
    "        \"is_quote\": int(token.is_quote),\n",
    "        \"is_head\": int(token.head.text == token.text),\n",
    "        \"is_alpha\": int(token.is_alpha),\n",
    "        \"is_digit\": int(token.is_alpha),\n",
    "        \"is_contain_upper\": contain_upper_fn(token),\n",
    "        \"is_punct\": int(token.is_punct),\n",
    "        \"is_end\": int(loc == sent_token_sum-1),\n",
    "        \"is_start\": int(loc == 0)\n",
    "    }\n",
    "    \n",
    "    # previous token feature\n",
    "    if loc > 0:\n",
    "        prev_token = sent[loc-1][0]\n",
    "        features[\"prev:pos\"] = prev_token.pos_\n",
    "        features[\"prev:dep\"] = prev_token.dep_\n",
    "        features[\"prev:like_num\"] = prev_token.like_num\n",
    "        features[\"prev:is_quote\"] = prev_token.is_quote\n",
    "        features[\"prev:is_head\"] = int(prev_token.head.text == prev_token.text)\n",
    "        features[\"prev:is_contain_upper\"] = contain_upper_fn(prev_token)\n",
    "        features[\"prev:is_punct\"] = prev_token.is_punct\n",
    "    \n",
    "    # next token feature\n",
    "    if loc != sent_token_sum-1:\n",
    "        next_token = sent[loc+1][0]\n",
    "        features[\"next:pos\"] = next_token.pos_\n",
    "        features[\"next:dep\"] = next_token.dep_\n",
    "        features[\"next:like_num\"] = next_token.like_num\n",
    "        features[\"next:is_quote\"] = next_token.is_quote\n",
    "        features[\"next:is_head\"] = int(next_token.head.text == next_token.text)\n",
    "        features[\"next:is_contain_upper\"] = contain_upper_fn(next_token)\n",
    "        features[\"next:is_punct\"] = next_token.is_punct\n",
    "    \n",
    "    if no_embedding:\n",
    "        features[\"lemma\"] = token.lemma_\n",
    "    else:\n",
    "        for n, dim_val in enumerate(token.vector):\n",
    "            features[\"vector-dim-{}\".format(n)] = dim_val\n",
    "    return features\n",
    "\n",
    "def sent_to_features(sent, no_embedding=False):\n",
    "    return [word_to_features(token, sent, no_embedding) for token, label in sent]\n",
    "\n",
    "def sent_to_labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent_to_tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [sent_to_features(s) for s in train_sents]\n",
    "y_train = [sent_to_labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent_to_features(s) for s in test_sents]\n",
    "y_test = [sent_to_labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Ransom Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Number of features ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = set([state for (state, attr) in crf.state_features_])\n",
    "len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "3.668192 O        detailed_pos:,\n",
      "3.546590 O        dep:aux\n",
      "3.155423 O        is_punct\n",
      "3.123099 O        detailed_pos:JJR\n",
      "2.803767 O        pos:ADV\n",
      "\n",
      "Top negative:\n",
      "-1.764894 B        prev:dep:pobj\n",
      "-1.844169 B        next:dep:poss\n",
      "-1.885828 B        dep:prep\n",
      "-2.902181 I        detailed_pos:VBZ\n",
      "-5.505717 I        is_start\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_state_features(state_features, expected_label=None):\n",
    "    for (attr, label), weight in state_features:\n",
    "        if expected_label is None or label == expected_label:\n",
    "            print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(5))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top OUTER Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "3.668192 O        detailed_pos:,\n",
      "3.546590 O        dep:aux\n",
      "3.155423 O        is_punct\n",
      "3.123099 O        detailed_pos:JJR\n",
      "2.803767 O        pos:ADV\n",
      "\n",
      "Top negative:\n",
      "-1.699270 O        prev:dep:oprd\n"
     ]
    }
   ],
   "source": [
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(5), expected_label=\"O\")\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-10:], expected_label=\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top BEGIN Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "2.085285 B        prev:dep:oprd\n",
      "1.805067 B        detailed_pos:AFX\n",
      "1.408623 B        vector-dim-158\n",
      "1.288349 B        prev:dep:relcl\n",
      "1.240862 B        prev:dep:csubj\n",
      "1.139142 B        vector-dim-235\n",
      "1.096165 B        prev:pos:INTJ\n",
      "\n",
      "Top negative:\n",
      "-1.604910 B        prev:is_quote\n",
      "-1.624057 B        dep:punct\n",
      "-1.632893 B        pos:PUNCT\n",
      "-1.764894 B        prev:dep:pobj\n",
      "-1.844169 B        next:dep:poss\n",
      "-1.885828 B        dep:prep\n"
     ]
    }
   ],
   "source": [
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(50), expected_label=\"B\")\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-10:], expected_label=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top INNER Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "2.698514 I        detailed_pos:RP\n",
      "2.061820 I        prev:pos:PRON\n",
      "1.854688 I        prev:dep:compound\n",
      "1.659597 I        prev:pos:ADV\n",
      "1.605263 I        next:dep:expl\n",
      "1.308960 I        detailed_pos:VB\n",
      "1.125533 I        vector-dim-158\n",
      "1.123998 I        vector-dim-119\n",
      "\n",
      "Top negative:\n",
      "-1.664534 I        is_end\n",
      "-2.902181 I        detailed_pos:VBZ\n",
      "-5.505717 I        is_start\n"
     ]
    }
   ],
   "source": [
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(50), expected_label=\"I\")\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-10:], expected_label=\"I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(y_test, y_pred, target_label):\n",
    "    def flatten_y(y):\n",
    "        y_output = set()\n",
    "        for n_sentence, y_sentence in enumerate(y):\n",
    "            for n_token, y_token in enumerate(y_sentence):\n",
    "                if y_token in target_label:\n",
    "                    y_output.add(\"{}-{}\".format(n_sentence, n_token))\n",
    "        return y_output\n",
    "    \n",
    "    y_test_set = flatten_y(y_test)\n",
    "    y_pred_set = flatten_y(y_pred)\n",
    "    y_intersect = y_test_set.intersection(y_pred_set)\n",
    "    \n",
    "    precision = len(y_intersect)/ len(y_pred_set) * 100\n",
    "    recall = len(y_intersect)/ len(y_test_set) * 100\n",
    "    f1 = 2*precision*recall / (precision+recall)\n",
    "    \n",
    "    return precision, recall, f1, len(y_test_set)\n",
    "\n",
    "def get_result(y_test, y_pred, target_labels=[\"B\", \"I\"]):\n",
    "    result_raw = {\n",
    "        \"label\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": [],\n",
    "        \"support\": []\n",
    "    }\n",
    "    for label in target_labels+[target_labels]:\n",
    "        if type(label) is str:\n",
    "            precision, recall, f1, support = evaluation(y_test, y_pred, [label])\n",
    "        else:\n",
    "            precision, recall, f1, support = evaluation(y_test, y_pred, label)\n",
    "        result_raw[\"label\"].append(label)\n",
    "        result_raw[\"precision\"].append(precision)\n",
    "        result_raw[\"recall\"].append(recall)\n",
    "        result_raw[\"f1\"].append(f1)\n",
    "        result_raw[\"support\"].append(support)\n",
    "    return pd.DataFrame(result_raw)[[\"label\", \"precision\", \"recall\", \"f1\", \"support\"]].set_index(\"label\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_term(tokens, labels, verbose=False):\n",
    "    if len(tokens) != len(labels):\n",
    "        raise ValueError(\"Size of label and token mismatch! {} Vs {}\".format(len(tokens), len(labels)))\n",
    "    aspect_terms = []\n",
    "    curr_term = \"\"\n",
    "    if verbose:\n",
    "        print(\"\\t\", tokens)\n",
    "        print(\"\\t\", labels)\n",
    "    for n in range(len(tokens)):\n",
    "        curr_label = labels[n]\n",
    "        curr_tokens = tokens[n]\n",
    "        curr_text = curr_tokens.text\n",
    "            \n",
    "        if curr_label == \"B\" or curr_label == \"I\":\n",
    "            curr_term += \" \" + curr_text\n",
    "        else:\n",
    "            if len(curr_term) > 0:\n",
    "                aspect_terms.append(curr_term.strip())\n",
    "                curr_term = \"\"\n",
    "    return aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>83.925234</td>\n",
       "      <td>68.759571</td>\n",
       "      <td>75.589226</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>86.337209</td>\n",
       "      <td>63.597430</td>\n",
       "      <td>73.242910</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[B, I]</th>\n",
       "      <td>89.761092</td>\n",
       "      <td>70.446429</td>\n",
       "      <td>78.939470</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision     recall         f1  support\n",
       "label                                           \n",
       "B       83.925234  68.759571  75.589226      653\n",
       "I       86.337209  63.597430  73.242910      467\n",
       "[B, I]  89.761092  70.446429  78.939470     1120"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(y_test=y_test, y_pred=y_pred, target_labels=[\"B\", \"I\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm result with function from sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B    0.83925   0.68760   0.75589       653\n",
      "          I    0.86337   0.63597   0.73243       467\n",
      "\n",
      "avg / total    0.84931   0.66607   0.74611      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=[\"B\", \"I\"], digits=5\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Target    0.89761   0.70446   0.78939      1120\n",
      "\n",
      "avg / total    0.89761   0.70446   0.78939      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_bin_label(labels):\n",
    "    for y_sent in labels:\n",
    "        yield [\"O\" if y == \"O\" else \"Target\" for y in y_sent]\n",
    "y_test_bin = list(to_bin_label(y_test))\n",
    "y_pred_bin = list(to_bin_label(y_pred))\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test_bin, y_pred_bin, labels=[\"Target\"], digits=5\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest\n",
    " - non-sequential classifier\n",
    " - scale invariant model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycrfsuite import ItemSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_INDEX = sorted(list(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_to_vector(sent, feature_index):\n",
    "    sent_features = ItemSequence(sent).items()\n",
    "    output = []\n",
    "    for token_feature in sent_features:\n",
    "        output.append([token_feature.get(f, 0) for f in feature_index])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vec = [sent_to_vector(x, FEATURE_INDEX) for x in X_train]\n",
    "X_test_vec = [sent_to_vector(x, FEATURE_INDEX) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(sent):\n",
    "    return [t for tokens in sent for t in tokens]\n",
    "\n",
    "X_train_vec_flat = flatten(X_train_vec)\n",
    "y_train_flat = flatten(y_train)\n",
    "\n",
    "X_test_vec_flat = flatten(X_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier()\n",
    "RF_clf.fit(X_train_vec_flat, y_train_flat)\n",
    "y_pred_RF_flat = RF_clf.predict(X_test_vec_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_y(flat_list, ref_list):\n",
    "    input_list = list(flat_list)\n",
    "    output = []\n",
    "    idx_from = 0\n",
    "    for n, y_sent in enumerate(ref_list):\n",
    "        idx_to = idx_from+len(y_sent)\n",
    "        output.append(input_list[idx_from:idx_to])\n",
    "        idx_from += len(output[-1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_feature_importances = list(zip(RF_clf.feature_importances_, FEATURE_INDEX))\n",
    "RF_feature_importances.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0533708662614 relative_loc\n",
      "0.0391753269525 vector-dim-17\n",
      "0.0254787031233 prev:dep:compound\n",
      "0.0217325515914 vector-dim-10\n",
      "0.0182564627003 pos:NOUN\n",
      "0.0158516118273 vector_l2_norm\n",
      "0.0144110452866 vector-dim-232\n",
      "0.0119619876673 vector-dim-9\n",
      "0.011783297662 prev:pos:NOUN\n",
      "0.00924481714129 vector-dim-99\n"
     ]
    }
   ],
   "source": [
    "for feature_name, importance in RF_feature_importances[:10]:\n",
    "    print(feature_name, importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>75.951557</td>\n",
       "      <td>67.228178</td>\n",
       "      <td>71.324127</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>77.542373</td>\n",
       "      <td>39.186296</td>\n",
       "      <td>52.062589</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[B, I]</th>\n",
       "      <td>88.083538</td>\n",
       "      <td>64.017857</td>\n",
       "      <td>74.146846</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision     recall         f1  support\n",
       "label                                           \n",
       "B       75.951557  67.228178  71.324127      653\n",
       "I       77.542373  39.186296  52.062589      467\n",
       "[B, I]  88.083538  64.017857  74.146846     1120"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_RF = reshape_y(y_pred_RF_flat, y_test)\n",
    "get_result(y_test=y_test, y_pred=y_pred_RF, target_labels=[\"B\", \"I\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B    0.75952   0.67228   0.71324       653\n",
      "          I    0.77542   0.39186   0.52063       467\n",
      "\n",
      "avg / total    0.76615   0.55536   0.63293      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred_RF, labels=[\"B\", \"I\"], digits=5\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF without Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_no_embedding = [sent_to_features(s, no_embedding=True) for s in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>52.091255</td>\n",
       "      <td>20.980092</td>\n",
       "      <td>29.912664</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>57.201646</td>\n",
       "      <td>29.764454</td>\n",
       "      <td>39.154930</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[B, I]</th>\n",
       "      <td>55.731225</td>\n",
       "      <td>25.178571</td>\n",
       "      <td>34.686347</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision     recall         f1  support\n",
       "label                                           \n",
       "B       52.091255  20.980092  29.912664      653\n",
       "I       57.201646  29.764454  39.154930      467\n",
       "[B, I]  55.731225  25.178571  34.686347     1120"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_no_embedding = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    min_freq=10\n",
    ")\n",
    "crf_no_embedding.fit(X_train_no_embedding, y_train)\n",
    "y_pred_no_embedding = crf_no_embedding.predict(X_test)\n",
    "get_result(y_test=y_test, y_pred=y_pred_no_embedding, target_labels=[\"B\", \"I\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B    0.52091   0.20980   0.29913       653\n",
      "          I    0.57202   0.29764   0.39155       467\n",
      "\n",
      "avg / total    0.54222   0.24643   0.33766      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred_no_embedding, labels=[\"B\", \"I\"], digits=5\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "5.815385 O        lemma:laptop\n",
      "5.305817 B        lemma:price\n",
      "5.160203 B        lemma:software\n",
      "4.924636 B        lemma:program\n",
      "4.829737 I        lemma:application\n",
      "\n",
      "Top negative:\n",
      "-1.866842 O        lemma:shut\n",
      "-1.880739 O        lemma:charge\n",
      "-2.151915 O        lemma:load\n",
      "-2.492014 O        lemma:carry\n",
      "-2.828713 O        lemma:ship\n"
     ]
    }
   ],
   "source": [
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf_no_embedding.state_features_).most_common(5))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf_no_embedding.state_features_).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
